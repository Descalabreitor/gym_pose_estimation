{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "PyAV is not installed, and is necessary for the video operations in torchvision.\nSee https://github.com/mikeboers/PyAV#installation for instructions on how to\ninstall PyAV on your system.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/barbell biceps curl/barbell biceps curl_61.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m n_frames_por_paquete \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 53\u001b[0m tensor_coordenadas, etiqueta \u001b[38;5;241m=\u001b[39m preprocesado(video_path, n_frames_por_paquete)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Imprime la forma del tensor resultante y la etiqueta\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForma del tensor de coordenadas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_coordenadas\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mpreprocesado\u001b[0;34m(video_path, n)\u001b[0m\n\u001b[1;32m     12\u001b[0m etiqueta \u001b[38;5;241m=\u001b[39m video_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Lee el video usando torchvision\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m video, _, _ \u001b[38;5;241m=\u001b[39m read_video(video_path, pts_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msec\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Número total de frames en el video\u001b[39;00m\n\u001b[1;32m     18\u001b[0m total_frames \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AAAIV/lib/python3.11/site-packages/torchvision/io/video.py:276\u001b[0m, in \u001b[0;36mread_video\u001b[0;34m(filename, start_pts, end_pts, pts_unit, output_format)\u001b[0m\n\u001b[1;32m    274\u001b[0m     vframes, aframes, info \u001b[38;5;241m=\u001b[39m _video_opt\u001b[38;5;241m.\u001b[39m_read_video(filename, start_pts, end_pts, pts_unit)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     _check_av_available()\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_pts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         end_pts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AAAIV/lib/python3.11/site-packages/torchvision/io/video.py:41\u001b[0m, in \u001b[0;36m_check_av_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_av_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(av, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m av\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/barbell biceps curl/barbell biceps curl_61.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m n_frames_por_paquete \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 53\u001b[0m tensor_coordenadas, etiqueta \u001b[38;5;241m=\u001b[39m preprocesado(video_path, n_frames_por_paquete)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Imprime la forma del tensor resultante y la etiqueta\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForma del tensor de coordenadas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_coordenadas\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mpreprocesado\u001b[0;34m(video_path, n)\u001b[0m\n\u001b[1;32m     12\u001b[0m etiqueta \u001b[38;5;241m=\u001b[39m video_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Lee el video usando torchvision\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m video, _, _ \u001b[38;5;241m=\u001b[39m read_video(video_path, pts_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msec\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Número total de frames en el video\u001b[39;00m\n\u001b[1;32m     18\u001b[0m total_frames \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AAAIV/lib/python3.11/site-packages/torchvision/io/video.py:276\u001b[0m, in \u001b[0;36mread_video\u001b[0;34m(filename, start_pts, end_pts, pts_unit, output_format)\u001b[0m\n\u001b[1;32m    274\u001b[0m     vframes, aframes, info \u001b[38;5;241m=\u001b[39m _video_opt\u001b[38;5;241m.\u001b[39m_read_video(filename, start_pts, end_pts, pts_unit)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     _check_av_available()\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_pts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         end_pts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AAAIV/lib/python3.11/site-packages/torchvision/io/video.py:41\u001b[0m, in \u001b[0;36m_check_av_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_av_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(av, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m av\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preprocesado(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/barbell biceps curl/barbell biceps curl_61.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mpreprocesado\u001b[0;34m(video_path, n)\u001b[0m\n\u001b[1;32m      9\u001b[0m pose_estimator \u001b[38;5;241m=\u001b[39m mp_pose\u001b[38;5;241m.\u001b[39mPose()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Lee el video usando torchvision\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m video, _, _ \u001b[38;5;241m=\u001b[39m read_video(video_path, pts_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msec\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Número total de frames en el video\u001b[39;00m\n\u001b[1;32m     15\u001b[0m total_frames \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AAAIV/lib/python3.11/site-packages/torchvision/io/video.py:276\u001b[0m, in \u001b[0;36mread_video\u001b[0;34m(filename, start_pts, end_pts, pts_unit, output_format)\u001b[0m\n\u001b[1;32m    274\u001b[0m     vframes, aframes, info \u001b[38;5;241m=\u001b[39m _video_opt\u001b[38;5;241m.\u001b[39m_read_video(filename, start_pts, end_pts, pts_unit)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     _check_av_available()\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_pts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         end_pts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AAAIV/lib/python3.11/site-packages/torchvision/io/video.py:41\u001b[0m, in \u001b[0;36m_check_av_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_av_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(av, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m av\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preprocesado(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/barbell biceps curl/barbell biceps curl_61.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m, in \u001b[0;36mpreprocesado\u001b[0;34m(video_path, n)\u001b[0m\n\u001b[1;32m      9\u001b[0m pose_estimator \u001b[38;5;241m=\u001b[39m mp_pose\u001b[38;5;241m.\u001b[39mPose()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Lee el video usando torchvision\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m video, _, _ \u001b[38;5;241m=\u001b[39m read_video(video_path, pts_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msec\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Número total de frames en el video\u001b[39;00m\n\u001b[1;32m     15\u001b[0m total_frames \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AAAIV/lib/python3.11/site-packages/torchvision/io/video.py:276\u001b[0m, in \u001b[0;36mread_video\u001b[0;34m(filename, start_pts, end_pts, pts_unit, output_format)\u001b[0m\n\u001b[1;32m    274\u001b[0m     vframes, aframes, info \u001b[38;5;241m=\u001b[39m _video_opt\u001b[38;5;241m.\u001b[39m_read_video(filename, start_pts, end_pts, pts_unit)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     _check_av_available()\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_pts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         end_pts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AAAIV/lib/python3.11/site-packages/torchvision/io/video.py:41\u001b[0m, in \u001b[0;36m_check_av_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_av_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(av, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m av\n",
      "\u001b[0;31mImportError\u001b[0m: PyAV is not installed, and is necessary for the video operations in torchvision.\nSee https://github.com/mikeboers/PyAV#installation for instructions on how to\ninstall PyAV on your system.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from torchvision.io import read_video\n",
    "\n",
    "def preprocesado(video_path, n):\n",
    "    # Inicializa el modelo de mediapipe para la estimación de pose\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose_estimator = mp_pose.Pose()\n",
    "\n",
    "    # Extrae la etiqueta del video del path (nombre sin extensión)\n",
    "    etiqueta = video_path.split('/')[-2]\n",
    "\n",
    "    # Lee el video usando torchvision\n",
    "    video, _, _ = read_video(video_path, pts_unit='sec')\n",
    "\n",
    "    # Número total de frames en el video\n",
    "    total_frames = video.size(0)\n",
    "\n",
    "    # Lista para almacenar las matrices de coordenadas relativas\n",
    "    matrices_coordenadas = []\n",
    "\n",
    "    # Itera sobre los frames con paso 'n'\n",
    "    for i in range(0, total_frames, n):\n",
    "        # Asegúrate de que no te salgas del rango\n",
    "        end_idx = min(i + n, total_frames)\n",
    "\n",
    "        # Extrae el paquete de frames\n",
    "        paquete = video[i:end_idx].permute(1, 0, 2, 3)\n",
    "\n",
    "        # Convierte el paquete a un array de NumPy\n",
    "        paquete_np = paquete.numpy()\n",
    "\n",
    "        # Infiere las poses en el paquete utilizando mediapipe\n",
    "        with mp_pose.Pose() as pose:\n",
    "            results = pose.process(paquete_np)\n",
    "\n",
    "        # Extrae las coordenadas relativas de los landmarks y las convierte a un array de NumPy\n",
    "        landmarks = np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.pose_landmarks.landmark])\n",
    "\n",
    "        # Normaliza las coordenadas relativas en un tensor\n",
    "        tensor_coordenadas = torch.tensor(landmarks)\n",
    "\n",
    "        # Agrega el tensor de coordenadas a la lista\n",
    "        matrices_coordenadas.append(tensor_coordenadas)\n",
    "\n",
    "    return torch.stack(matrices_coordenadas), etiqueta\n",
    "\n",
    "# Ejemplo de uso\n",
    "video_path = \"data/barbell biceps curl/barbell biceps curl_61.mp4\"\n",
    "n_frames_por_paquete = 10\n",
    "\n",
    "tensor_coordenadas, etiqueta = preprocesado(video_path, n_frames_por_paquete)\n",
    "\n",
    "# Imprime la forma del tensor resultante y la etiqueta\n",
    "print(f\"Forma del tensor de coordenadas: {tensor_coordenadas.shape}\")\n",
    "print(f\"Etiqueta del video: {etiqueta}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAAIV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
